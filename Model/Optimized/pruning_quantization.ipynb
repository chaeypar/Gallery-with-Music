{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niEr6xb2wRxZ",
        "outputId": "3ad64bda-4be1-4453-d037-a81eb46f2e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.23.5)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.5\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mHeevyFkp4cc"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "wfBs9ggHqz8O"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras import regularizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvSiFTtDuC30",
        "outputId": "559f137d-f2c3-43a7-d148-4e0f1c9c2c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = './train/'\n",
        "test_dir = './test/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training')\n",
        "validation_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "vZx9FFZDq7Pu"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"fer_model.h5\"\n",
        "model = load_model(checkpoint_path)\n",
        "\n",
        "weight_decay = 1e-4\n",
        "num_classes = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQMFaCDvvpku",
        "outputId": "f68303be-74e3-4178-df13-fb5e3379698d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "359/359 [==============================] - 32s 66ms/step - loss: 0.4718 - accuracy: 0.8673 - val_loss: 1.5378 - val_accuracy: 0.6187\n",
            "Epoch 2/5\n",
            "359/359 [==============================] - 24s 66ms/step - loss: 0.4831 - accuracy: 0.8627 - val_loss: 1.4390 - val_accuracy: 0.6152\n",
            "Epoch 3/5\n",
            "359/359 [==============================] - 23s 63ms/step - loss: 0.4976 - accuracy: 0.8595 - val_loss: 1.4868 - val_accuracy: 0.6184\n",
            "Epoch 4/5\n",
            "359/359 [==============================] - 23s 63ms/step - loss: 0.5053 - accuracy: 0.8542 - val_loss: 1.4589 - val_accuracy: 0.6234\n",
            "Epoch 5/5\n",
            "359/359 [==============================] - 23s 65ms/step - loss: 0.5101 - accuracy: 0.8501 - val_loss: 1.4264 - val_accuracy: 0.6208\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd54c60b550>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "initial_sparsity = 0.5\n",
        "final_sparsity = 0.8\n",
        "\n",
        "num_train_samples = training_set.samples\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "steps_per_epoch = np.ceil(num_train_samples / batch_size).astype(np.int32)\n",
        "\n",
        "begin_step = 0\n",
        "end_step = steps_per_epoch * num_epochs\n",
        "\n",
        "\n",
        "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
        "    initial_sparsity=initial_sparsity,\n",
        "    final_sparsity=final_sparsity,\n",
        "    begin_step=begin_step,\n",
        "    end_step=end_step\n",
        ")\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
        "\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(loss='categorical_crossentropy', optimizer=Adam(0.0003), metrics=['accuracy'])\n",
        "model_for_pruning.fit(training_set, epochs=5, validation_data=validation_set, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRdTUkCb7EGC",
        "outputId": "364943b5-579d-4019-d6a7-c34290976786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112/112 [==============================] - 3s 25ms/step - loss: 1.3898 - accuracy: 0.6313\n",
            "Test accuracy = 63.12779188156128%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test accuracy = {model_for_pruning.evaluate(test_set ,batch_size=test_set.batch_size,steps=test_set.n // test_set.batch_size)[1]*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIixczDgrTcx",
        "outputId": "4f20432c-9506-4efa-c43b-2c02191729e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "model_for_export.save('pruned_model.h5')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('pruned_fer_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkog9-8B8dSv",
        "outputId": "29a9b6a0-ddce-4374-91e0-5695110c7bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original model size: 5266152 bytes\n",
            "Pruned model size: 1337264 bytes\n",
            "Pruned Ratio = 74.6064298941618%\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('fer_model.h5')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('fer_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "def get_tflite_model_size(file_path: str) -> int:\n",
        "    size_bytes = os.path.getsize(file_path)\n",
        "    return size_bytes\n",
        "\n",
        "original_model_size = get_tflite_model_size('fer_model.tflite')\n",
        "pruned_model_size = get_tflite_model_size('pruned_fer_model.tflite')\n",
        "print(f\"Original model size: {original_model_size} bytes\")\n",
        "print(f\"Pruned model size: {pruned_model_size} bytes\")\n",
        "\n",
        "print(f\"Pruned Ratio = {(1-pruned_model_size/original_model_size)*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjE-AetR9P9D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
